[pytest]
# Test discovery patterns
python_files = test_*.py *_test.py tests.py
python_classes = Test* *Tests
python_functions = test_*

# Test directories
testpaths = tests
norecursedirs = .git .tox dist build *.egg node_modules __pycache__ .venv

# Pytest plugins and options
addopts = 
    --strict-markers
    --tb=short
    --cov=src/clarity
    --cov-report=term-missing:skip-covered
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=65
    --maxfail=1
    --disable-warnings
    -p no:warnings
    --durations=10
    --color=yes
    -vv

# Markers for test categorization
markers =
    unit: Unit tests that run in isolation
    integration: Integration tests that interact with external services
    functional: End-to-end functional tests
    performance: Performance and load tests
    slow: Tests that take longer than 5 seconds
    smoke: Critical smoke tests for deployment validation
    aws: Tests that require AWS services
    ml: Machine learning model tests
    critical: Critical path tests that must pass

# Coverage configuration
[coverage:run]
source = src/clarity
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */conftest.py
    */migrations/*
    */.venv/*

[coverage:report]
precision = 2
show_missing = True
skip_covered = True
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @overload
    @abstractmethod

[coverage:html]
directory = htmlcov

[coverage:xml]
output = coverage.xml

# Asyncio configuration
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Logging configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Timeout configuration
timeout = 300
timeout_method = thread

# Parallel execution
[tool:pytest]
# Number of workers for parallel execution (use -n auto for automatic detection)
# This is configured via pytest-xdist plugin