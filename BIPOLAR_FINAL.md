# Computational Approaches for Bipolar Disorder Monitoring (Bipolar I & II)

## Background: Bipolar I vs II and Monitoring Challenges

Bipolar disorder (BD) is characterized by oscillating mood episodes of depression and elevated mood. In **Bipolar I**, patients experience full manic episodes (extreme euphoria or irritability often requiring hospitalization), whereas **Bipolar II** involves **hypomanic** episodes (milder mania) alongside depression. Some patients also experience **mixed episodes** where depressive and manic symptoms coexist. Early detection of mood swings is crucial for timely intervention, but traditionally this relies on self-reports or clinical visits. Monitoring BD in real life is challenging because mood states can shift rapidly and unpredictably. This has spurred interest in **computational methods** – using data from wearables and smartphones – to continuously track physiological and behavioral patterns as objective proxies for mood state. Recent advances in **digital phenotyping** suggest that subtle changes in daily patterns (sleep, activity, etc.) can serve as early warning signals of impending mood episodes in BD patients.

## Wearables and Digital Biomarkers in Bipolar Disorder

Modern wearables (like smart rings and fitness trackers) passively capture data on sleep, activity, heart rate and more. **Sleep disruption** is one of the most important signals in bipolar disorder. In fact, for *three out of four* people with BD, **sleep problems are the most common signal** that a manic episode is about to occur. Reduced need for sleep is a hallmark of (hypo)mania, and sleep deprivation (or jet lag) can even **trigger** manic/hypomanic episodes. Conversely, during bipolar depression, excessive sleep or irregular sleep-wake cycles are common. Wearable devices make it feasible to track these changes continuously. For example, an Oura Ring study of 164 bipolar patients found that **subtle fluctuations in sleep and activity levels began to show unusual variability a few days before** a hypomanic episode. On average, **sleep changes were detected \~3 days before** an episode, and activity changes about 2.5 days before it. Notably, *within-day* patterns (like 12-hour cycles) were especially predictive of mood shifts: variability in 12-hour sleep patterns achieved \~87% accuracy in flagging oncoming hypomania, and activity-pattern variability reached \~89% (both with sensitivity >90%). In other words, it’s not just absolute sleep duration that matters – **spikes in day-to-day or even half-day variability** are key signals of instability. These findings align with a dynamic-systems view of mood: a relatively stable routine can suddenly destabilize, manifesting as large swings in sleep or activity when a mood episode is looming.

Several specific **digital biomarkers** have emerged as useful in bipolar monitoring:

* **Sleep and Circadian Rhythms:** Changes in total sleep, sleep timing, and sleep consistency are critical. A 2024 study in *NPJ Digital Medicine* showed that using **only sleep-wake data** from wearables can accurately predict next-day mood episodes (depressive, manic, or hypomanic) – with AUCs of 0.80 for depression and up to 0.98 for mania. Interestingly, **circadian phase shifts** (changes in the timing of one’s daily sleep/activity cycle) were the most significant predictors: **phase delays** in sleep onset were linked to upcoming depressive episodes, whereas **phase advances** (shifting sleep schedule earlier) signaled manic episodes. These circadian disruptions are consistent with clinical lore that maintaining regular routines helps prevent mood swings.

* **Physical Activity:** Wearable accelerometers (in watches, rings, phones) track steps and general activity level. In bipolar depression, activity typically drops (fatigue, psychomotor slowing), while in mania/hypomania many patients become overactive or restless. Crucially, *variability* in activity is a better indicator than average levels. A 2025 study of 127 bipolar outpatients using a smart ring found that **day-to-day variability in step count** was the **earliest warning sign of a depressive episode**, increasing about **7 days before** symptom onset. This lead time was significantly longer than the 4-day advance warning provided by changes in sleep duration. In other words, **activity patterns started to change a full week before patients themselves recognized rising depression**, highlighting how wearables can enable proactive intervention. For (hypo)mania, activity spikes or restless movements may similarly foreshadow episodes, though some studies have found mixed results. Still, monitoring gross motor activity and energy expenditure can feed into detection algorithms.

* **Heart Rate and Physiological Signals:** While not as extensively reported as sleep/activity, wearables also capture heart rate (HR) and related measures (HR variability, etc.). Elevated baseline heart rate or altered daily HR patterns could reflect mood changes (e.g. increased arousal in mania, or lethargy in depression). Some research suggests combining heart rate with sleep and steps improves predictions, though simpler models focusing on sleep alone already perform impressively. Other physiological markers like skin temperature or galvanic skin response might add value, but the goal is often to stick with readily available metrics (sleep and activity) for practicality.

* **Behavioral and Phone-Use Patterns:** Beyond wearables, smartphones contribute additional data streams: frequency of phone calls or texts, GPS mobility, screen time, voice features, etc. Prior pilot studies (e.g. the **SIMBA** study) found that **decreased communication and reduced mobility** tended to accompany rising bipolar depression, whereas **increased social messaging** sometimes correlated with manic symptoms. These signals can complement wearable data, though they require phone sensing rather than a pure wearable. For the scope of a wearable-centric backend, such phone data might be optional, but it’s worth noting that multi-modal monitoring (wearable + phone) has shown promise in detecting mood changes.

## Machine Learning Models and Results

Researchers have applied various **machine learning (ML)** techniques to these wearable-derived features to detect or even predict bipolar mood episodes. A recent example is Lipschitz et al. (2025), who collected Fitbit data from 54 BD patients over 9 months along with bi-weekly mood ratings. They trained several ML models to recognize two-week periods with clinically significant depression or (hypo)mania (defined by standard questionnaire score cutoffs). Their best model was a **Binary Mixed Model (BiMM) forest**, an ensemble method that incorporates mixed-effects to personalize predictions. In testing, this model achieved an ROC–AUC of **86.0% for detecting depression** and **85.2% for (hypo)mania** from passive data. At optimal thresholds, the model’s accuracy was about **80% for depression** (71% sensitivity, 86% specificity) and **89% for (hypo)mania** (80% sensitivity, 90% specificity). These are robust results, indicating that purely passive data (steps, sleep, etc. with minimal preprocessing) can classify mood states with high fidelity. Importantly, the authors emphasized their approach was **“designed for broad application,”** requiring only off-the-shelf wearables and standard questionnaires for training labels. This suggests such models could generalize to typical patients, not just highly monitored research subjects, moving the field toward practical clinical tools.

Another notable study by Lim et al. (2024) focused on *forecasting* episodes using simpler inputs. They developed personalized mathematical models using **only sleep-wake features** (from smartphone or wearable data) combined with each patient’s history of mood episodes. Despite using a single data modality (sleep patterns), their model could predict the **next day’s mood state** with striking accuracy – reported AUCs of **0.80 for depression**, **0.95 for hypomania**, and **0.98 for full mania**. The most powerful predictors were those capturing **circadian rhythm shifts** (i.e. changes in the timing of sleep/activity cycles) – specifically, **phase delays presaged depressive episodes while phase advances signaled mania**. This high accuracy for manic episodes is encouraging, though it’s worth noting that full mania (as in Bipolar I) often involves very dramatic behavior changes, which may be easier to predict than subtler shifts. Nonetheless, the success of this model using limited data types is promising for “out-of-the-box” deployment, since it avoids the complexity of multi-sensor integration.

It’s important to recognize that most ML models in this domain are **supervised**, meaning they require labeled examples of mood episodes to train on. This typically entails patients self-reporting mood symptoms (e.g. via questionnaires like PHQ-9 for depression or ASRM for mania) to serve as ground truth. In a real-world setting, assembling such labeled data for each new user can be difficult. Some studies address this by using a **personalized** modeling approach – training an algorithm on each individual’s own data stream (rather than a one-size-fits-all model). Personalized ML can adapt to a person’s baseline and yield more sensitive detection of changes. For instance, the Lipschitz et al. study effectively created individualized decision forests (the BiMM accounts for random effects per person) and saw improved performance. There is also research into **population-level vs. personalized models**: one protocol (Wang et al., 2023) is explicitly comparing whether pooling data from many users vs. tailoring models to each user yields better accuracy for mental health indicators. Early indications are that personalization enhances sensitivity to an individual’s unique patterns, though general models provide a useful starting point when personal data is sparse.

## Rule-Based Strategies and Data Limitations

Your question notes that **no labeled data is available**, so purely ML-driven solutions are tricky initially. In such cases, **rule-based algorithms** informed by clinical knowledge and research findings can be implemented in the backend as a starting point. Fortunately, many of the findings above can be distilled into actionable rules or anomaly-detection logic:

* **Sleep Loss Alerts:** Since sleep reduction often precedes mania, the system can flag if a user’s total sleep drops below a certain threshold (e.g. <4 hours) for 2 nights in a row or if sleep duration varies wildly compared to their baseline. For bipolar patients, even one night of significantly curtailed sleep can be meaningful. A rule might be: “if sleep decreases by >30% from average for 2 consecutive days, increase mania risk score.” This doesn’t require any training data – it’s a heuristic from clinical observation.

* **Circadian Shift Detection:** Implement logic to monitor the timing of sleep or activity peaks each day. If a person’s sleep onset or wake-up time shifts significantly earlier or later than usual over a short period, it could indicate mood change. For example, a sudden **phase advance** (waking much earlier with high energy) might trigger a mania warning, while a **phase delay** (sleeping in much later or insomnia at night) might warn of depression. These rules can be based on deviation from a 2-week moving average of mid-sleep time, for instance.

* **Activity Variability Spike:** Using an algorithm for **change-point detection** on the activity time series can identify sudden increases or decreases in daily activity levels. The 2025 study by Ortiz et al. used a method called *time-frequency spectral derivative spike detection* to objectively flag when a significant change occurred in the activity pattern. A simpler implementation could be: “if daily step count (or energy expenditure) changes by more than X standard deviations from the past month’s mean, and this persists for a couple of days, signal a potential transition.” This approach is essentially unsupervised – it looks for **anomalies or regime changes** in the data, which is exactly what an oncoming mood episode would produce. Notably, Ortiz et al. found that such activity spikes gave about **one week’s advance notice** of depression onset, beating even sleep-based rules. So a backend service might continuously analyze variability and issue an alert like “possible downward mood shift starting” when it detects a sustained drop in activity regularity.

* **Composite Early Warning Score:** A rule-based system can also combine multiple signals into a simple score. For example, assign points for each warning sign (sleep loss, high day-to-day variability in sleep or steps, etc.) and if the score crosses a threshold, alert the user or clinician. This is analogous to how some **relapse prevention apps** for BD work – e.g., the MONARCA system in earlier research allowed patients and clinicians to define personal warning signs and tracked them via phone sensors and self-reports. In an automated way, your backend could integrate wearable data streams to do something similar, using the literature-based markers.

The advantage of rule-based or anomaly-based methods is that they **“work out of the box”** without requiring a custom ML model for each user. They leverage general knowledge about bipolar prodromes (early symptoms) and known digital biomarkers. However, you can also update these rules as you gather real user data – essentially *bootstrapping* a dataset. Over time, if some users do self-report mood changes, that data can be used to refine or even train a machine learning model specific to your population. But initially, the above heuristic approach provides a high-quality starting point grounded in reputable research findings.

## Considerations: Bipolar Subtypes and Mixed States

The approaches discussed apply to **both Bipolar I and II**, as both involve cyclical mood changes that manifest in sleep/activity patterns. Most wearable studies do not distinguish algorithms for BD I vs BD II – they either include both (e.g. the Oura Ring study included patients with bipolar I or II) or focus on the general phenomena of mania/hypomania and depression. The main difference is one of **degree**: Bipolar I manic episodes are more extreme, so signals like total sleepless nights or extremely elevated activity might be more pronounced. Bipolar II hypomania might show as moderate reductions in sleep and a smaller uptick in activity. A well-calibrated system could potentially assign different threshold sensitivities: e.g. trigger on smaller changes for a known BD II patient to catch hypomania, whereas for BD I patients the changes might be very obvious. But overall, the **same types of markers (sleep loss, circadian disruption, increased variability)** are relevant to both subtypes of the illness.

**Mixed episodes**, where symptoms of depression and mania occur together, are trickier to detect because the data signals could be conflicting (e.g. a patient is agitated and sleepless but also feeling hopeless – clinically mixed state). There is relatively little explicit research on detecting mixed states via wearables, likely because mixed episodes are less common and harder to label. One might expect a mixed state to show some markers of mania (reduced sleep) *and* markers of depression (perhaps lower overall activity or erratic patterns). The rule-based system might flag both kinds of warnings in such a scenario. Future research is indeed looking at whether the same digital phenotyping patterns hold for depressive episodes **and mixed states**. As of 2025, the focus has been on pure depression or (hypo)mania, but it’s reasonable to include general knowledge of mixed episodes in your system – for example, if a user’s sleep drops (mania-sign) but their self-reported mood or maybe speech sentiment (if available) indicates depression, the combination could suggest a mixed episode. In the absence of labeled data, you could at least ensure the system doesn’t force an episode classification and can say “multiple mood signals are activated, consider a mixed state or complex episode.”

## Moving Forward

In summary, **computational bipolar monitoring** is an emerging reality, thanks to wearables and smart devices. Incorporating proven digital biomarkers – especially sleep duration/variability, circadian rhythm shifts, and activity patterns – will give your backend a strong foundation. Several high-quality studies have demonstrated that these signals can predict mood episodes in bipolar disorder with around **80–90% accuracy**, sometimes providing **days of advance warning**. We’ve discussed how to translate those findings into practical rules (e.g. alert on large sleep changes, detect spikes in activity variability) that can work without proprietary data. As you build out the system, you might also keep an eye on open-source datasets or tools: for example, the multi-modal **MODMA** dataset is being developed for mental health analysis (currently focused on depression), and projects like **TIMEBASE** are investigating digital biomarkers specifically in BD. These may soon yield shareable models or data. Additionally, researchers in computational psychiatry are exploring **mathematical models of mood dynamics** (treating mood as an oscillatory system with random “kindling” perturbations). Such models, while theoretical, reinforce why we see sudden shifts and could eventually inform personalized predictions of mood cycles.

For now, leveraging the existing knowledge base provides a **ready-to-use** solution. By integrating wearable-derived insights (sleep, activity, circadian cues) and rule-based detection of anomalies, you can deploy a “banger” version of a bipolar monitoring system that works out-of-the-box. This system would continuously look for the telltale signs of impending manic or depressive episodes and flag them for users or healthcare providers – potentially improving outcomes through early intervention. As more data comes in, the approach can be refined or supplemented with machine learning, but even the **no-data** initial state can be covered with high-quality, evidence-driven heuristics from the bipolar computational psychiatry literature.

**Sources:** Recent studies and reviews on bipolar digital phenotyping and computational models were used to compile these insights. Key references include wearable sensing studies in *Acta Psychiatrica Scandinavica* (2025), *npj Digital Medicine* (2024), *Journal of Affective Disorders* (2025), and *International Journal of Bipolar Disorders* (2025), as well as summaries of bipolar disorder sleep research. These provide a reputable foundation for the recommended models and rules.

Got it. I’ll now synthesize an advanced implementation improvement dossier focused on what’s possible *right now* in the backend—using only existing Apple HealthKit data and PAT model outputs.

I’ll evaluate how to enhance your current bipolar monitoring module using features like sleep duration, onset latency, circadian rhythm, HR/HRV if available, and activity—translating recent literature into backend-implementable rules and heuristics. I’ll return shortly with a comprehensive, execution-ready upgrade plan.


# Digital Phenotyping Approaches for Bipolar Disorder Monitoring

## Overview: Bipolar Disorder and the Need for Monitoring

Bipolar disorder (BD) is characterized by pathological mood swings between depressive and manic/hypomanic episodes. In BD type I, patients experience full manic episodes, while type II involves hypomania (a less severe form of mania) alongside depression; the clinical picture can also include mixed states (simultaneous symptoms of mania and depression) and persistent mood instability. These mood fluctuations impact sleep, energy, activity, and behavior. **Digital phenotyping** – continuous monitoring of behavior via personal devices – has emerged as a promising tool to *early identify and manage* mood episodes in BD. By passively tracking data like sleep patterns, physical activity, and phone usage, clinicians hope to detect warning signs of impending mania or depression sooner than traditional assessments. Recent research, though still developing, suggests that individualized, sensor-driven monitoring could enable more *precision psychiatry* in BD, allowing personalized interventions when a patient’s digital behavior deviates from their healthy baseline.

## Wearable Sensors and Rest-Activity Patterns

Wearable devices (such as fitness trackers or smartwatches) provide continuous measures of sleep and activity, which are core features affected in bipolar mood episodes. **Actigraphy** studies (using wearables to measure movement and rest) show clear differences: depressive phases tend to feature *longer sleep duration and lower daytime activity*, whereas manic phases often show *reduced sleep need* and more **variable** or erratic activity patterns. For example, a systematic review found BD patients had significantly prolonged sleep latency and higher total sleep during depressive episodes (sometimes *predicting* impending mania when sleep patterns suddenly change), while mania was associated with unpredictable bursts of activity within the day. These rhythmic disruptions are so characteristic that experts see actigraphy-based metrics as a potential *digital biomarker* for BD – a way to detect or even forecast mood shifts.

One major signal is the **circadian rhythm** of sleep and wake times. A recent 2024 study demonstrated that by extracting features from just a person’s daily sleep-wake schedule (via smartphone or wearable), one can accurately predict next-day mood episodes. The model derived 36 circadian and sleep features and achieved high predictive accuracy for depressive, manic, and hypomanic episodes (area-under-curve = 0.80, 0.98, 0.95 respectively). Notably, *shifts in daily circadian timing* were the strongest predictors: **phase delays** in sleep (i.e. staying up or waking later than usual) tended to precede depressive episodes, whereas **phase advances** (shifting sleep/wake earlier and sleeping less) heralded manic episodes. This aligns with clinical observations that decreased need for sleep and earlier rising often signal impending mania, while oversleeping or delayed routines accompany depression.

Beyond sleep, overall activity metrics from wearables are informative. A 2025 study by Lipschitz et al. had 54 bipolar patients wear Fitbits for 9 months and used the data to train machine-learning classifiers for mood states. The best model (a personalized “BiMM forest” ensemble) could detect two-week periods of significant depression or (hypo)mania with \~85% **ROC-AUC** accuracy. In test data, it achieved \~86% AUC for depression and 85% for mania, corresponding to about 80% sensitivity/86% specificity for depression and 80%/90% for (hypo)mania at the optimal threshold. This confirms that *consumer wearable data alone* (steps, sleep duration, heart rate etc.) can produce robust mood predictions outside the clinic. The authors note this approach required only passive data and minimal filtering, moving toward algorithms suitable for broad patient populations without special sensors. Consistent with other findings, it underscores that even *coarse-grained* signals like daily step counts or sleep logs carry enough information to infer mood symptom severity.

**Location and mobility** data, which can be obtained via phone GPS or wearable, also correlate with mood. In one study, researchers tracked GPS location patterns of bipolar patients for 3 months and could detect **depressive episodes with 85% accuracy using location features alone**. Depressed periods were characterized by patients’ reduced mobility – e.g. spending more time at home or fewer distinct locations – compared to euthymic periods. This suggests that a simple location-based metric (like “distance traveled per day”) can serve as a proxy for psychomotor retardation common in bipolar depression. Interestingly, some findings about **manic mobility** are somewhat counterintuitive: one pilot monitoring study found that *increases* in manic symptoms were actually preceded by **decreased** physical movement as captured via phone sensors. However, at the same time those impending manic episodes showed **increased social interaction** digitally (more outgoing calls/texts). In other words, a manic patient might become very talkative and engaged on the phone while not necessarily travelling far – perhaps due to restlessness focused in place. By contrast, the study saw that worsening depression was foreshadowed by both **declining activity levels** (less distance traveled) *and* reduced social communication (fewer texts sent). These patterns highlight how a combination of passive signals can jointly characterize mood changes: e.g. *low movement + low communication = depression*, whereas *low movement + high communication = mania* in that dataset.

## Smartphone Behavioral Markers (Phone Usage, Typing, and Speech)

Modern smartphones continuously generate rich behavioral data that can be mined for mental health insights. **Phone usage patterns** – such as frequency of calls and texts, app usage, typing dynamics, and daily routine regularity – have shown distinctive signatures for different mood states in BD. Research from the MONARCA project (a smartphone monitoring system for bipolar patients) found that certain objectively measured phone behaviors differed significantly between euthymic vs. symptomatic periods, and even between bipolar patients and healthy individuals. For instance, bipolar patients (even when in a stable mood) tended to make *more frequent calls and texts per day* than healthy controls, and these metrics fluctuated with mood episodes. In a clinical trial, the MONARCA app was able to pick up **early warning signs** of impending mania/hypomania – such as changes in sleep and activity reported via the phone – before full-blown episodes occurred. (Notably, it was less effective for catching depressive relapses early, reflecting the fact that depression onset may be more gradual or harder to distinguish from “normal” low activity.) Still, these findings support that *passive smartphone data can alert to mood shifts*, especially for mania which often causes sharper deviations from baseline behavior.

Specific smartphone metrics have been studied in detail. **Typing dynamics** (keystroke metadata) provide a window into a person’s cognitive and motor state. The BiAffect study collected metadata from a custom smartphone keyboard in bipolar subjects, measuring things like typing speed, rhythm, errors, and autocorrect usage. Using this data, researchers developed a deep learning model called “DeepMood” that could predict mood disturbance levels with high accuracy – in fact, *just one minute of typing data* could yield a reliable estimate of depression severity in their pilot test. Patterns in typing were found to change with mood: for example, manic or mixed states correlated with *more erratic typing* (e.g. increased typo rates, faster but more fragmented keypress sequences) and often a shift in **diurnal usage** (typing more at night), whereas depression was linked to slower, more lethargic typing patterns and possibly reduced overall keyboard activity. Indeed, one 8-week study reported that each mood state – depression, mania, or mixed – was associated with a **distinct fingerprint of phone interactions**. During manic phases, people tended to have **more frequent phone sessions**, greater phone movement (via accelerometer), and a higher rate of keyboard errors, often with a skew toward late-night activity; during depressive phases, the opposite trend was observed (fewer phone interactions, less mobility, more daytime inactivity). Mixed episodes showed their own combination of these changes. Such findings suggest that by monitoring *how* and *when* a person uses their phone (not just how much), one can infer their neuropsychological state.

Besides typing and usage logs, **voice and speech patterns** captured via smartphones are another promising signal. Research with apps that record speech (e.g. phone call audio or voice diaries) indicates that vocal characteristics change with mood elevation or decline. For example, studies have analyzed outgoing phone call audio in bipolar patients and found that **acoustic features** like pitch (fundamental frequency), amplitude variability, speech rate, and even the ratio of spoken words to silence can differentiate mood states. In manic states, patients often exhibit faster, louder speech with higher pitch and reduced pauses (reflecting pressure of speech), whereas in depression, speech can be slower, softer, and monotonic. One small study identified that features such as increased speaking length per turn, higher pitch *and* a higher **harmonics-to-noise ratio** (a measure of voice quality) were among the best differentiators of mood – these tended to increase during mania/hypomania and normalize or drop during euthymia and depression. Although capturing and analyzing voice data requires more effort (and raises privacy considerations), it can add an additional layer of insight beyond physical activity and phone usage. In fact, when multiple modalities are combined – say, sleep/activity from wearables, phone usage logs, and voice or **GPS** data – the predictive power tends to improve. A recent study of 291 individuals using a bipolar tracking app showed that *multimodal* models outperformed single-source models: incorporating smartphone **accelerometer** data (which reflects general motion and device handling) boosted mood prediction accuracy by \~5% compared to using only clinical questionnaires and typing metrics. This implies that different data streams (physical movement, keyboard interaction, etc.) each capture a piece of the mood symptom puzzle, and together they can paint a more complete and accurate picture of a patient’s mental state.

## “Out-of-the-Box” Strategies: Rule-Based Monitoring vs. ML Models

Implementing a digital mood monitoring system for bipolar disorder can follow two broad approaches: **knowledge-driven (rule-based)** algorithms or **machine learning** models. Given that our goal is an approach that “works out of the box” without requiring extensive patient-specific training data, a sensible strategy is to leverage the *established biomarkers and rules* identified by the research above.

**Rule-Based Monitoring:** This involves coding expert-derived rules or thresholds based on known early warning signs of mood episodes. For example, one could program the system to continuously watch a patient’s baseline and trigger alerts if certain changes exceed a threshold:

* **Sleep Reduction:** If average nightly sleep duration drops by a certain amount (e.g. > 2 hours less than usual for several nights), or if the individual’s sleep schedule suddenly **shifts earlier** by a large margin, flag a potential mania/hypomania risk. Conversely, if sleep duration increases dramatically or the person is **active much later into the night** (phase delay), flag a potential depression onset.
* **Activity Level Changes:** Monitor daily step counts or overall physical activity. A sustained *increase* in energy (far above personal baseline) combined with decreased sleep could foreshadow mania. On the other hand, a significant *decrease* in daytime activity (e.g. prolonged low movement for days) might indicate a depressive swing. Sudden variability (highly irregular active/rest periods) is also a red flag for mood instability.
* **Social Interaction and Communication:** Track metrics like number of phone calls, texts, or social media interactions. **Spike in outgoing communications** (numerous calls/messages, especially at odd hours) can be an early warning of mania-related hyper-social behavior. **Withdrawal** or drop-off in communication frequency may accompany depressive episodes. Similarly, changes in message tone or length (if accessible via metadata) might be considered.
* **Routine Disruption:** Using phone sensors to calculate a **social rhythm metric (SRM)** – essentially how regular the person’s daily routine is – can be useful. Research has shown that features like daily location variance, total distance traveled, and timing of activities can be used to infer the stability of one’s routine. Large deviations from routine (erratic mealtimes, inconsistent sleep/wake, irregular location patterns) often precede mood episodes in BD. Thus, a rule-based system could raise an alert when an individual’s inferred daily rhythm becomes unusually irregular, signaling that their circadian routine is breaking down.
* **Combined Patterns:** Some rules may involve combinations of signals. As noted, a pattern of *low physical activity coupled with high nighttime phone usage* could be an early sign of mania, whereas *low activity coupled with low phone usage* suggests depression. By defining such composite conditions (based on evidence from studies), a rule-based engine can capture the nuanced differences between mood states better than any single metric alone.

The advantage of rule-based methods is that they are **transparent and interpretable** – clinicians and patients can understand why a certain alert was triggered (e.g. “your average sleep has dropped 3 hours below baseline for 4 days”). They also don’t necessarily require large training datasets, which suits a context of limited labeled data. Many of the above rules come directly from clinical research and could be implemented from day one using default threshold values, then refined over time for each individual. In practice, an initial calibration period (perhaps a few weeks to establish personal baselines for sleep, activity, etc.) would enhance the accuracy of these rules. After that, the system could function largely on *anomaly detection* – flagging significant deviations from one’s normal patterns that match the profile of mania or depression.

**Machine Learning Models:** On the other hand, data-driven ML approaches have demonstrated impressive accuracy in identifying mood episodes, but they typically require training data (historical examples of the person’s mood states with corresponding sensor data). If labeled data are scarce, fully supervised models are hard to apply immediately. However, there are **personalized ML techniques** and even some unsupervised methods that could be adapted. For instance, the Fitbit-based **BiMM forest model** trained by Lipschitz et al. achieved \~85% accuracy in classifying mood windows, but it was trained on each patient’s own prior months of data and mood reports – a luxury not available when starting fresh. In our scenario, one could instead leverage *pre-trained* models or population-level models as a starting point. Some studies have hinted at generalizable classifiers: e.g. Grünerbl et al. developed a smartphone-sensing system that could automatically distinguish **manic vs. depressed states** and even detect state **transitions** in bipolar patients with minimal per-patient training. Their system combined multiple sensor streams (calls, motion, GPS, etc.) and was able to recognize mood state changes *without lengthy calibration*, suggesting an underlying model that generalized well across users. This kind of approach – perhaps using algorithms like anomaly detection, clustering, or transfer learning – could be incorporated such that the model “learns” typical patterns from external datasets or published model weights, then adjusts to the individual. Indeed, open datasets (for example, the open-science bipolar data used in the 2022 accelerometer study) or previously trained models could provide a baseline model that our backend could import. While fully open-source mood prediction models are still emerging, the field is moving toward sharing of algorithms; for example, researchers have published frameworks for mood prediction and even deep learning architectures (like DeepMood for typing data) that we could draw inspiration from. If any pre-trained weights or models are obtainable (some groups may release code on GitHub or via publications), we can integrate those into our system and then fine-tune with whatever user data becomes available over time.

In summary, a **hybrid approach** might work best initially: encode the well-known rules (sleep change, activity change, etc.) for immediate, interpretable monitoring, and in parallel gradually accumulate user data to train/refine more complex ML models tailored to each person. This way, the system offers a strong “out-of-the-box” safety net grounded in bipolar digital biomarkers, yet can evolve and improve its accuracy as it learns from real usage. The good news from the literature is that even with *no proprietary data*, we have a wealth of high-quality research to guide the system’s logic. Studies consistently point to a set of actionable digital indicators for bipolar mood shifts – **circadian rhythm disruptions, activity level changes, and social/communication behavior changes** are recurrent themes – which we can immediately leverage in our backend. As we incorporate these findings, our solution for monitoring BD type I and II (and even detecting mixed states) can be built on a firm, evidence-based foundation. By continuously tracking these signals via wearables and smartphones, the system can provide early warnings of mood instability and facilitate proactive interventions, essentially creating a “digital early warning system” for bipolar relapse based on the latest computational psychiatry insights.
