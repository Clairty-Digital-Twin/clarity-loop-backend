# CLARITY-AI Models & Machine Learning

CLARITY-AI uses cutting-edge AI models to transform raw health data into actionable insights. This document details our ML pipeline, model architectures, and performance characteristics.

## Model Architecture Overview

```mermaid
flowchart TB
    subgraph Input ["üìä Raw Health Data Input"]
        HK[HealthKit Export<br/>JSON Data]
        Sensors[Multi-sensor Data<br/>HR, Steps, Sleep, HRV]
        Context[User Context<br/>Demographics, History]
    end
    
    subgraph Preprocessing ["‚öôÔ∏è Data Preprocessing Pipeline"]
        Valid[Data Validation<br/>‚úÖ Schema Checking]
        Clean[Data Cleaning<br/>üßπ Outlier Removal]
        Norm[Normalization<br/>üìä Z-score, Min-Max]
        Align[Temporal Alignment<br/>‚è∞ 1-min Intervals]
        Feature[Feature Engineering<br/>üîß Signal Processing]
    end
    
    subgraph PAT ["üß† PAT Transformer Model"]
        Embed[Temporal Embedding<br/>üìà Time Series ‚Üí Vectors]
        Pos[Positional Encoding<br/>üïê Circadian Awareness]
        Attn[Multi-Head Attention<br/>üëÅÔ∏è 8 Attention Heads]
        Layers[Transformer Layers<br/>üîó Deep Learning Stack]
        SleepHead[Sleep Analysis Head<br/>üò¥ Sleep Quality Scores]
        CircHead[Circadian Head<br/>üåô Rhythm Analysis]
    end
    
    subgraph Gemini ["üíé Gemini AI Integration"]
        PromptEng[Prompt Engineering<br/>üìù Context Building]
        LLM[Gemini Pro Model<br/>ü§ñ Large Language Model]
        PostProc[Post-processing<br/>‚ú® Response Refinement]
        NLG[Natural Language Generation<br/>üí¨ Human-readable Insights]
    end
    
    subgraph Fusion ["üîó Multi-Modal Fusion"]
        Combine[Feature Combination<br/>üîÄ PAT + Metadata]
        Weight[Attention Weighting<br/>‚öñÔ∏è Importance Scoring]
        Ensemble[Ensemble Methods<br/>üéØ Model Averaging]
    end
    
    subgraph Output ["üéØ Analysis Outputs"]
        Metrics[Quantitative Metrics<br/>üìä Sleep Quality, HRV]
        Insights[Natural Language Insights<br/>üìù Explanations]
        Recommendations[Personalized Recommendations<br/>üí° Actionable Advice]
        Alerts[Health Alerts<br/>üö® Anomaly Detection]
    end
    
    %% Data Flow - Main Pipeline
    HK --> Valid
    Sensors --> Clean
    Context --> Norm
    Valid --> Clean --> Norm --> Align --> Feature
    
    %% PAT Processing Branch
    Feature --> Embed --> Pos --> Attn --> Layers
    Layers --> SleepHead
    Layers --> CircHead
    
    %% Gemini Processing Branch
    Feature --> PromptEng --> LLM --> PostProc --> NLG
    
    %% Fusion Process
    SleepHead --> Combine
    CircHead --> Combine
    Context --> Weight
    Combine --> Weight --> Ensemble
    
    %% Output Generation
    Ensemble --> Metrics
    NLG --> Insights
    Ensemble --> Recommendations
    SleepHead --> Alerts
    
    %% Cross-connections
    Metrics --> PromptEng
    CircHead --> PromptEng
    
    %% Styling - Bold colors with white text
    classDef input fill:#ff9900,stroke:#e65100,stroke-width:2px,color:white
    classDef preprocess fill:#2196f3,stroke:#0d47a1,stroke-width:2px,color:white
    classDef pat fill:#4caf50,stroke:#1b5e20,stroke-width:2px,color:white
    classDef gemini fill:#9c27b0,stroke:#4a148c,stroke-width:2px,color:white
    classDef fusion fill:#ff5722,stroke:#bf360c,stroke-width:2px,color:white
    classDef output fill:#607d8b,stroke:#263238,stroke-width:2px,color:white
    
    class HK,Sensors,Context input
    class Valid,Clean,Norm,Align,Feature preprocess
    class Embed,Pos,Attn,Layers,SleepHead,CircHead pat
    class PromptEng,LLM,PostProc,NLG gemini
    class Combine,Weight,Ensemble fusion
    class Metrics,Insights,Recommendations,Alerts output
```

### Data Flow Summary

**Input**: HealthKit exports (heart rate, sleep, activity, HRV)  
**Processing**: PAT transformer + Google Gemini AI  
**Output**: Health pattern analysis with natural language explanations

## PAT (Pretrained Actigraphy Transformer) Deep Dive

```mermaid
flowchart TD
    subgraph InputLayer ["üì• INPUT PROCESSING"]
        A[7-DAY ACTIVITY WINDOW<br/>10,080 time points<br/>1-minute sampling]
        B[DATA NORMALIZATION<br/>Z-score standardization<br/>NHANES population stats]
        C[MISSING VALUE HANDLING<br/>Forward fill + interpolation<br/>Quality score tracking]
    end
    
    subgraph EmbeddingLayer ["üî§ EMBEDDING LAYER"]
        D[TEMPORAL EMBEDDING<br/>1D Conv layers<br/>Position-aware encoding]
        E[CIRCADIAN FEATURES<br/>Sin/cos time encoding<br/>24-hour cycle awareness]
        F[FEATURE FUSION<br/>Concatenate embeddings<br/>Learnable projection]
    end
    
    subgraph TransformerStack ["üß† TRANSFORMER ARCHITECTURE"]
        G[MULTI-HEAD ATTENTION<br/>8 parallel attention heads<br/>Global temporal patterns]
        H[FEED-FORWARD NETWORK<br/>Position-wise processing<br/>ReLU activation]
        I[LAYER NORMALIZATION<br/>Residual connections<br/>Gradient stability]
        J[DROPOUT REGULARIZATION<br/>0.1 dropout rate<br/>Overfitting prevention]
    end
    
    subgraph OutputHeads ["üéØ SPECIALIZED OUTPUT HEADS"]
        K[SLEEP QUALITY HEAD<br/>Regression output<br/>0-1 quality score]
        L[SLEEP STAGE HEAD<br/>4-class classification<br/>REM/Deep/Light/Wake]
        M[CIRCADIAN HEAD<br/>Phase + amplitude<br/>Rhythm disruption score]
        N[ANOMALY DETECTION<br/>Reconstruction loss<br/>Health alert triggers]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    H --> I
    I --> J
    J --> K
    J --> L
    J --> M
    J --> N
    
    classDef input fill:#ff9900,stroke:#e65100,stroke-width:3px,color:white
    classDef embed fill:#2196f3,stroke:#0d47a1,stroke-width:3px,color:white
    classDef transformer fill:#4caf50,stroke:#1b5e20,stroke-width:3px,color:white
    classDef output fill:#9c27b0,stroke:#4a148c,stroke-width:3px,color:white
    
    class A,B,C input
    class D,E,F embed
    class G,H,I,J transformer
    class K,L,M,N output
```

### Model Specifications

**Architecture Details:**

- **Model Type**: Transformer with temporal encoding
- **Input Size**: 10,080 time points (7 days √ó 24 hours √ó 60 minutes)
- **Context Length**: Up to 2 weeks of continuous data
- **Parameters**: ~12M parameters
- **Attention Heads**: 8 multi-head attention layers

### Input Processing

**Data Preprocessing Pipeline:**

1. **Temporal Alignment**: All data resampled to 1-minute intervals
2. **Outlier Removal**: Physiological bounds filtering
3. **Normalization**: Population-based z-scores using NHANES data
4. **Feature Engineering**: Movement proxy vector generation

**Input Format:**

```python
{
  "actigraphy_sequence": [0.1, 0.3, 2.1, ...],  # 10,080 points
  "heart_rate_sequence": [1.2, 1.1, 1.4, ...],  # Normalized
  "metadata": {
    "sampling_rate": 60,  # seconds
    "duration_hours": 168,
    "user_demographics": {...}
  }
}
```

### Model Outputs

**Sleep Analysis Results:**

```python
{
  "sleep_quality_score": 0.78,        # 0-1 scale
  "circadian_rhythm_stability": 0.85,  # Consistency metric
  "sleep_efficiency": 0.82,           # Time asleep / time in bed
  "predicted_sleep_stages": [
    {
      "start": "2025-06-01T23:00:00Z",
      "end": "2025-06-01T23:15:00Z", 
      "stage": "light",
      "confidence": 0.92
    }
  ],
  "anomalies": [
    {
      "timestamp": "2025-06-02T03:00:00Z",
      "type": "unusual_activity",
      "severity": "low",
      "description": "Unexpected movement during deep sleep"
    }
  ]
}
```

### Performance Metrics

**‚ö†Ô∏è IMPORTANT DISCLAIMER**:

- **NOT FDA APPROVED** or clinically validated for medical use
- **RESEARCH AND EDUCATIONAL PURPOSES ONLY**
- **NOT for medical diagnosis or treatment decisions**
- Open source project using academic research models

**Technical Performance (Development Environment)**:

- **Inference Time**: ~15 seconds for 7-day analysis
- **Memory Usage**: 2.1GB peak during inference
- **Batch Processing**: Up to 50 users simultaneously

### Research Foundation

**Academic Basis**:

- Based on Dartmouth College PAT research (CC BY-4.0)
- Uses publicly available pretrained transformer weights
- Implements academic methodologies for educational demonstration
- **No clinical validation studies have been conducted**

**Study Context**:

- PAT research paper: "AI Foundation Models for Wearable Movement Data"
- Original model trained on research datasets
- Our implementation is for demonstration and learning purposes only

---

## 2. Gemini AI Integration

### Overview

Google's Gemini Pro provides the natural language processing layer for CLARITY, enabling conversational health insights and personalized recommendations.

### Integration Architecture

**Service Layer:**

```python
class GeminiService:
    def __init__(self):
        self.model = genai.GenerativeModel("gemini-1.5-flash")
        self.context_manager = HealthContextManager()
        
    async def generate_insight(self, health_data, context):
        prompt = self._build_health_prompt(health_data, context)
        response = await self.model.generate_content(prompt)
        return self._parse_health_response(response)
```

### Prompt Engineering

**Health Data Context Prompt:**

```python
HEALTH_ANALYSIS_PROMPT = """
You are a health AI assistant analyzing wearable device data. 

User Health Summary:
- Sleep efficiency: {sleep_efficiency}%
- Average heart rate: {avg_hr} bpm
- HRV trend: {hrv_trend}
- Activity level: {activity_score}/100

PAT Model Analysis:
- Sleep quality score: {sleep_quality}/100
- Circadian stability: {circadian_score}%
- Detected anomalies: {anomalies}

User Question: {user_question}

Provide:
1. Direct answer based on the data
2. Explanation of relevant patterns
3. Actionable recommendations
4. Follow-up questions to explore

Keep responses conversational but scientifically accurate.
"""
```

### Response Processing

**Structured Output Parsing:**

```python
def parse_gemini_response(response_text):
    return {
        "summary": extract_summary(response_text),
        "recommendations": extract_recommendations(response_text),
        "follow_up_questions": extract_questions(response_text),
        "confidence": calculate_confidence(response_text),
        "relevant_metrics": extract_metrics(response_text)
    }
```

### Conversation Management

**Multi-turn Context:**

```python
class ConversationManager:
    def __init__(self):
        self.conversation_history = []
        self.health_context = {}
        
    async def process_message(self, message, user_id):
        # Add current health context
        context = await self.get_user_health_context(user_id)
        
        # Build conversation prompt with history
        prompt = self.build_contextual_prompt(
            message, 
            self.conversation_history[-5:],  # Last 5 exchanges
            context
        )
        
        response = await self.gemini_service.generate(prompt)
        self.conversation_history.append((message, response))
        
        return response
```

---

## 3. Health Data Fusion

### Multi-modal Integration

**Fusion Architecture:**

```python
class HealthFusionModel:
    def __init__(self):
        self.pat_encoder = PATEncoder()
        self.vital_encoder = VitalSignsEncoder()  
        self.fusion_layer = CrossModalAttention()
        
    def forward(self, actigraphy, vitals, demographics):
        # Encode each modality
        activity_features = self.pat_encoder(actigraphy)
        vital_features = self.vital_encoder(vitals)
        
        # Cross-modal attention fusion
        fused = self.fusion_layer(activity_features, vital_features)
        
        return self.prediction_head(fused, demographics)
```

### Feature Engineering

**Time-series Features:**

```python
def extract_temporal_features(time_series_data):
    return {
        # Statistical features
        "mean": np.mean(time_series_data),
        "std": np.std(time_series_data),
        "skewness": scipy.stats.skew(time_series_data),
        
        # Frequency domain
        "dominant_frequency": find_dominant_frequency(time_series_data),
        "spectral_entropy": calculate_spectral_entropy(time_series_data),
        
        # Circadian features
        "circadian_strength": calculate_circadian_rhythm(time_series_data),
        "phase_shift": detect_phase_shift(time_series_data),
        
        # Complexity measures
        "sample_entropy": calculate_sample_entropy(time_series_data),
        "detrended_fluctuation": dfa_analysis(time_series_data)
    }
```

---

## 4. Model Training & Validation

### Training Data

**‚ö†Ô∏è DISCLAIMER**: This project does NOT train models from scratch.

### Implementation Approach

<!-- markdownlint-disable-next-line MD036 -->
**‚ö†Ô∏è RESEARCH/EDUCATIONAL USE ONLY**

#### What We Do

- Load pretrained PAT transformer weights from academic research
- Implement preprocessing pipeline per published specifications
- Provide API wrapper for demonstration purposes
- Follow CC BY-4.0 license requirements for attribution

#### What We DON'T Do

- Train models from scratch
- Collect proprietary health datasets  
- Conduct clinical validation studies
- Provide medical-grade analysis

#### Technical Implementation

- Model loading and inference pipeline
- Data preprocessing and normalization
- API endpoints for educational demos
- Research attribution and licensing compliance

### Training Methodology

**PAT Training Process:**

```python
def train_pat_model():
    # 1. Self-supervised pretraining on activity patterns
    pretrain_on_unlabeled_data(
        data=raw_actigraphy_sequences,
        task="masked_sequence_modeling",
        epochs=100
    )
    
    # 2. Supervised fine-tuning on sleep labels
    finetune_on_labeled_data(
        data=expert_labeled_sleep_data,
        task="sleep_stage_classification",
        epochs=50
    )
    
    # 3. Domain adaptation for different devices
    domain_adapt_for_devices(
        devices=["apple_watch", "fitbit", "garmin"],
        epochs=20
    )
```

### Model Validation

**Cross-validation Strategy:**

- **Temporal Splits**: Train on 2022 data, validate on 2023
- **User-stratified**: Ensure no user appears in both train/test
- **Device-stratified**: Balanced representation across device types

**Validation Metrics:**

```python
validation_metrics = {
    "accuracy": 0.924,
    "precision": 0.918,
    "recall": 0.931,
    "f1_score": 0.924,
    "auc_roc": 0.956,
    "cohen_kappa": 0.891  # Agreement with expert labels
}
```

---

## 5. Model Deployment & Serving

### Production Infrastructure

**Model Serving Architecture:**

```python
class ModelServingPipeline:
    def __init__(self):
        self.pat_model = load_optimized_model("pat-v2.1")
        self.gemini_client = GeminiClient()
        self.preprocessor = HealthDataPreprocessor()
        
    async def predict(self, raw_health_data):
        # Preprocess
        processed = await self.preprocessor.transform(raw_health_data)
        
        # PAT inference
        pat_results = await self.pat_model.predict(processed)
        
        # Gemini insight generation
        insights = await self.gemini_client.generate_insights(
            pat_results, processed
        )
        
        return {
            "quantitative": pat_results,
            "qualitative": insights,
            "generated_at": datetime.utcnow()
        }
```

### Performance Optimization

**Model Optimization Techniques:**

- **Quantization**: FP16 precision for 2x speedup
- **Batch Processing**: Dynamic batching for throughput
- **Caching**: Redis cache for common patterns
- **GPU Acceleration**: CUDA-optimized inference

**Production Metrics:**

```python
production_performance = {
    "p50_latency_ms": 850,
    "p95_latency_ms": 2100,
    "p99_latency_ms": 4500,
    "throughput_qps": 45,
    "gpu_utilization": 0.73,
    "error_rate": 0.002
}
```

---

## 6. Model Monitoring & Updates

### Real-time Monitoring

**Model Drift Detection:**

```python
class ModelDriftMonitor:
    def __init__(self):
        self.baseline_distribution = load_baseline_stats()
        
    def detect_drift(self, recent_predictions):
        # Statistical tests for distribution shift
        ks_statistic = stats.ks_2samp(
            self.baseline_distribution,
            recent_predictions
        )
        
        if ks_statistic.pvalue < 0.01:
            self.trigger_retraining_alert()
```

**Performance Tracking:**

- **Daily accuracy reports** against held-out validation set
- **User feedback integration** (thumbs up/down on insights)
- **Clinical outcome correlation** where available
- **A/B testing** for model versions

### Continuous Learning

**Model Update Pipeline:**

```python
async def continuous_learning_pipeline():
    # 1. Collect new labeled data
    new_data = await collect_recent_annotations()
    
    # 2. Validate data quality
    if validate_data_quality(new_data):
        
        # 3. Incremental training
        updated_model = await incremental_train(
            base_model=current_production_model,
            new_data=new_data
        )
        
        # 4. A/B test new model
        await deploy_shadow_model(updated_model)
        
        # 5. Gradual rollout if performance improves
        if shadow_model_performance > production_performance:
            await gradual_rollout(updated_model)
```

---

## 7. Research & Innovation

### Current Research Projects

#### 1. Multimodal Health Prediction

- Integrating wearable data with smartphone sensors
- Social context (calendar, location) for stress prediction
- Environmental factors (weather, air quality) correlation

#### 2. Personalized Model Adaptation

- Few-shot learning for individual sleep patterns
- Transfer learning across similar user profiles
- Federated learning for privacy-preserving personalization

#### 3. Clinical Decision Support

- Early detection of sleep disorders
- Mental health state prediction
- Medication adherence tracking

### Future Roadmap

#### Q1 2025

- PAT v3.0 with attention mechanism improvements
- Real-time anomaly detection
- Multi-device fusion (Apple Watch + Oura + CGM)

**Q2 2025**:

- Predictive health modeling (7-day forecasts)
- Integration with electronic health records
- Clinical trial partnership for validation

**Q3 2025**:

- Enhanced sleep disorder detection
- Multi-device data fusion improvements
- Advanced circadian rhythm analysis

**Q4 2025**:

- Real-time health alert system
- Predictive health modeling
- Integration with additional wearable devices

**Q1 2026**:

---

## Important Disclaimers

‚ö†Ô∏è **RESEARCH PLATFORM ONLY** - Not for medical diagnosis or treatment  
‚ö†Ô∏è **NO CLINICAL VALIDATION** - Educational and research purposes only  
‚ö†Ô∏è **NOT FDA APPROVED** - Consult healthcare providers for medical decisions  
‚ö†Ô∏è **ACADEMIC USE** - Built on open research, not proprietary validation  

## System Architecture

**Technical Implementation:**

- **PAT Model Loading**: Academic weights from Dartmouth research
- **Data Processing**: NHANES-normalized preprocessing pipeline  
- **Natural Language**: Google Gemini integration for conversational insights
- **Storage**: AWS DynamoDB with health data encryption

**Development Status:**

- **Tests**: 807/810 passing (99.6% success rate)
- **Coverage**: 57% code coverage (target: 85%)
- **API**: 44 endpoints for health data processing
- **Infrastructure**: AWS ECS production deployment ready

---

**Next**: Read [Deployment Guide](../operations/deployment.md) for production setup instructions
